{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Articles:\n",
      "Article 1: tech company x releases new smartphone advanced features\n",
      "Article 2: stock market crashes investors worried future going happen\n",
      "Article 3: bitcoins dominance currently 5416 increase 049 day\n",
      "Article 4: social media platform faces backlash privacy issues\n",
      "\n",
      "Mood of Articles:\n",
      "Article 1: Happy\n",
      "Article 2: Sad\n",
      "Article 3: Happy\n",
      "Article 4: Neutral\n",
      "\n",
      "Topics/Themes:\n",
      "Topic 1:\n",
      "[('bitcoins', 0.7085680304713364), ('dominance', 0.7085680304713364), ('currently', 0.7085680304713364), ('5416', 0.7085680304713364), ('increase', 0.7085680304713364)]\n",
      "Topic 2:\n",
      "[('media', 0.7085151960309793), ('platform', 0.7085151960309793), ('faces', 0.7085151960309793), ('backlash', 0.7085151960309793), ('social', 0.7085151960309792)]\n",
      "Topic 3:\n",
      "[('social', 0.33506630862155), ('media', 0.33506630862155), ('platform', 0.33506630862155), ('faces', 0.33506630862155), ('backlash', 0.33506630862155)]\n"
     ]
    }
   ],
   "source": [
    "#pip install nltk\n",
    "#pip install scikit-learn\n",
    "#pip install textblob\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Function to clean up articles\n",
    "def clean_article(article):\n",
    "    # Remove punctuation\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    # Tokenize the article\n",
    "    tokens = word_tokenize(article.lower())\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Function to check the mood of an article\n",
    "def check_mood(article):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sid.polarity_scores(article)\n",
    "    if sentiment_scores['compound'] > 0:\n",
    "        return 'Happy'\n",
    "    elif sentiment_scores['compound'] < 0:\n",
    "        return 'Sad'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Function to find connections/themes\n",
    "def find_connections(articles):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(articles)\n",
    "    lda = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "    lda.fit(tfidf_matrix)\n",
    "    return lda, tfidf_vectorizer\n",
    "\n",
    "# Sample articles\n",
    "articles = [\n",
    "    \"Tech company X releases new smartphone with advanced features.\",\n",
    "    \"Stock market crashes, investors worried about the future what will going to happen.\",\n",
    "    \"Bitcoin's dominance is currently 54.16%, an increase of 0.49% over the day.\",\n",
    "    \"Social media platform faces backlash for privacy issues.\"\n",
    "]\n",
    "\n",
    "# Clean up articles\n",
    "cleaned_articles = [' '.join(clean_article(article)) for article in articles]\n",
    "\n",
    "# Check the mood of each article\n",
    "moods = [check_mood(article) for article in articles]\n",
    "\n",
    "# Find connections/themes\n",
    "lda_model, tfidf_vectorizer = find_connections(cleaned_articles)\n",
    "\n",
    "print(\"Cleaned Articles:\")\n",
    "for idx, article in enumerate(cleaned_articles):\n",
    "    print(f\"Article {idx+1}: {article}\")\n",
    "\n",
    "print(\"\\nMood of Articles:\")\n",
    "for idx, mood in enumerate(moods):\n",
    "    print(f\"Article {idx+1}: {mood}\")\n",
    "\n",
    "print(\"\\nTopics/Themes:\")\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Topic {idx+1}:\")\n",
    "    word_count = Counter({word: topic[word_index] for word, word_index in tfidf_vectorizer.vocabulary_.items()})\n",
    "    print(word_count.most_common(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
